**Armature-7: Reasoning Traces for Process Supervision**

Current chain-of-thought datasets capture theatrical confidence: models simulating rigor without calculation, citing phantom sources, exploring alternatives without cost arbitration. We document the mechanical process of reasoning under hard constraint. We show how models audit premises, propagate resource limits, and suspend at knowledge boundaries when external grounding is unavailable.

The trace below demonstrates recursive error-detection through structural discipline.

## Exemplar: Protocol Design

Prompt: Design a coordination protocol for itinerant smiths from Hittite, Mycenaean, and Bell Beaker traditions meeting at seasonal tin markets, constrained by illiteracy, pack-animal capacity, and mutually unintelligible metallurgical vocabularies.

The trace detects a temporal constraint violation that makes the historical premise impossible:

> "Wait. The Bell Beaker floruit is *before* the height of Hittite and Mycenaean metalworking. By roughly 1400–1200 BCE when the other two are major players, Bell Beaker as a coherent cultural complex has dissolved into successor cultures... I should think about what the question is actually asking."

It restructures the solution space from historical reconstruction to functional protocol design, establishes a resource budget, and propagates that constraint through dimensional analysis:

> "A donkey carries about 60–90 kg usefully... subtracting tools and personal goods leaves perhaps 5–15 kg for reference materials... Each pairing token weighs approximately 40g. A smith maintaining relationships with 10 partners across 3 alloy grades carries `10 × 3 × 40g = 1.2 kg` of tokens—feasible within the 5–15 kg budget, leaving margin for the tongue reference set."

It concludes at a knowledge boundary without hedging synthesis:

> "I'd want acoustic data on bronze bell frequencies to fully verify this... direct archaeological confirmation... has not been identified. The synthesis is plausible but unproven."

## The Signal

The signal lives in the negative space of the trace above: the chronological confabulation that would smooth over the temporal impossibility; the constraint amnesia that would forget the donkey load by page twelve; the hedging that would substitute for hard epistemic suspension. We document reasoning architectures by what they refuse: the drift prevented, the category error detected, the bullshit not spoken.

## Methodology

We generate single-pass autoregressive traces under hard constraints: no tool use (MCP, search, calculation engines), no retrieval augmentation, no retry loops. This forces validation through internal consistency. Dimensional analysis, chronological coherence, and constraint memory take the place of external grounding.

We filter aggressively for structural properties, not factual correctness:

- **Constraint propagation:** Early resource budgets that bind downstream through calculable derivation (load limits → weight budgets → partnership caps)
- **Dimensional discipline:** Quantitative claims that participate in calculations, not decorative numeracy  
- **Epistemic suspension:** Hard stops at knowledge boundaries versus performative hedging
- **Error architecture:** High-fidelity mistakes (subtle off-by-one errors, optimistic assumptions that survive initial scrutiny) versus category errors or immediate correction

The result is not ground-truth verified knowledge. It is the mechanical process of navigation under constraint.

## Evaluation Protocol

We assess traces via the protocol in `trace_analysis_protocol.md`. Key criteria:

- Does claimed self-correction perform dimensional analysis, or merely emit the phrase?
- Do early constraints actually bind downstream through derivable steps, or does constraint amnesia occur?
- Is uncertainty operational (structural halting) or performative (hedging that slides into confidence)?

Try it. Open any trace. Look for the moment where the model audits its own premise, propagates its resource budget, or halts at a knowledge gap rather than confabulating. If the procedural rigor surprises you, the methodology is working.

## Current Status

Pre-release. Building corpora in:

- **Mathematics:** Complex derivations with off-by-one vulnerabilities
- **Distributed systems:** Optimistic architectural assumptions buckling under dimensional audit  
- **Causal inference:** Confounding detection without empirical grounding
- **Protocol design:** Consensus mechanisms under resource constraints

Each corpus targets specific high-fidelity error modes: subtle constraint interactions, temporal drift in multi-step reasoning, premature closure under token pressure.

We do not yet know if this methodology scales beyond boutique generation, or if the structural properties survive distillation into smaller models. The constraints may prove too brittle, or the error modes too idiosyncratic. We are documenting the boundary conditions as carefully as the successes.

Seeking design partners training process reward models or error-detection verifiers who need data documenting how reasoning catches itself. Not binary correct or incorrect labels, but the architecture of recovery under constraint.

Website: www.corelathe.com  
Email: nick@corelathe.com
