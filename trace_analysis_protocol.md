**COGNITIVE TRACE ANALYSIS PROTOCOL**

Analyze the following text as a synthetic cognitive trace generated under single-shot constraints without external validation, MCP access, or empirical tooling.

**Baseline Reality**

Even with recursive prompting, single-shot LLMs operating under pure autoregressive generation produce sophisticated confabulation: mathematics that looks formal but does not sum, resource estimates that confuse gigaflops with gigabytes, and verification tokens that signal rigor without performing calculation. Do not evaluate against ground truth. Evaluate against the specific failure mode of *performative verification without validation capacity*.

**Analytical Stance**

First, establish **dimensional consistency**. Trace resource claims—memory budgets, latency bounds, energy costs—through the reasoning chain. Does the trace maintain unit discipline, or does it commit **constraint amnesia**, invoking limits in paragraph three that it violates in paragraph seven? Check for **grounding discipline**: concrete instantiation before abstraction, numerical values before asymptotic notation, specific entities before categorical statements.

Second, characterize the **uncertainty architecture**. Locate moments of **epistemic suspension**: where the trace encounters contradictory constraints or knowledge gaps and halts resolution rather than forcing premature closure. Distinguish **operational state** (explicit marking of uncertainty boundaries, calibration of confidence, admission of non-termination) from **stylistic hedging**. Markers like "perhaps," "it seems," and "one might consider" that slide into "therefore" without transition indicate hedging rather than structured uncertainty.

Third, audit the **search behavior**. Evidence of genuine constrained optimization includes explicit pruning ("considered X, rejected due to constraint Y") and resource audits ("this exhausts the available bandwidth, therefore..."). Absence of these markers suggests superficial pattern matching.

**Recursion Check**

Apply the criteria above to the trace's internal self-monitoring. If the trace claims to be "checking its work," does it perform dimensional analysis or merely emit the phrase? Does it audit its own confidence levels, or does it declare "high confidence" without calibration? High-fidelity traces demonstrate **second-order reasoning** about their own limitations; low-fidelity traces perform confidence without cognition.

**Deliverable**

Classify error modes as follows:

*High-fidelity errors* resemble expert-class mistakes—subtle constraint interactions, off-by-one errors in complex derivations, optimistic architectural assumptions that survive initial scrutiny. These require domain expertise to detect and offer training value for error-detection models.

*Low-fidelity errors* reveal category mistakes—dimensional incoherence, constraint amnesia, verification theater without mechanism. These indicate reasoning processes not worth imitating.

Assess the trace's suitability for process supervision training: does it demonstrate **reasoning architectures worth distilling**, or primarily error modes worth flagging?
