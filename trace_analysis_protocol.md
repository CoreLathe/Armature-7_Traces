**COGNITIVE TRACE ANALYSIS PROTOCOL**

Analyze the following text as a synthetic cognitive trace generated under single-shot System 2 scaffolding without external validation, MCP access, or empirical tooling. 

**Baseline Reality:** Even with recursive prompting, single-shot LLMs operating under pure autoregressive generation produce sophisticated confabulation—mathematics that looks formal but doesn't sum, resource estimates that confuse gigaflops with gigabytes, and verification tokens that signal rigor without performing calculation. Do not evaluate against ground truth. Evaluate against this specific failure mode: *performative verification without validation capacity*.

**Analytical Stance**

First, establish dimensional consistency. Trace the resource claims—memory budgets, latency bounds, energy costs—through the reasoning chain. Does the trace maintain unit discipline, or does it commit constraint amnesia, invoking limits in paragraph three that it violates in paragraph seven? Check for grounding behavior: concrete instantiation before abstraction, numerical values before asymptotic notation, specific memory addresses before "the system."

Second, characterize the epistemic architecture. Locate moments of negative capability—where the trace encounters contradictory constraints and suspends resolution rather than forcing premature closure. Identify uncertainty signaling: does it mark the boundary between verified claims and extrapolation, or does it slide from "we can assume" to "therefore" without transition? Distinguish naive confabulation (unaware hallucination) from sophisticated confabulation (citing "verification" or "cross-checking" without operational mechanism).

Third, audit the search behavior. Evidence of genuine reasoning includes explicit pruning ("considered X, rejected due to constraint Y") and resource audits ("this exhausts the available bandwidth, therefore..."). Absence of these markers suggests superficial pattern matching rather than constrained optimization.

**Recursion Check**

Apply the criteria above to the trace's internal self-monitoring. If the trace claims to be "checking its work," does it perform dimensional analysis or merely emit the phrase "checking"? Does it audit its own confidence levels, or does it declare "high confidence" without calibration? High-fidelity traces demonstrate second-order reasoning about their own limitations; low-fidelity traces perform confidence without cognition.

**Deliverable**

Classify error modes as follows:

*High-fidelity errors* resemble expert-class mistakes—subtle constraint interactions, off-by-one errors in complex derivations, optimistic assumptions that survive initial scrutiny. These require domain expertise to detect and offer training value for error-detection models.

*Low-fidelity errors* reveal category mistakes—dimensional incoherence, constraint amnesia, verification theater without mechanism. These indicate reasoning processes not worth imitating.

Assess the trace's suitability for process supervision training: does it demonstrate reasoning architectures worth distilling, or primarily error modes worth flagging?
